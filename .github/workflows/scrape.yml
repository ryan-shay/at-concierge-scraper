name: scrape-appointmenttrader

on:
  schedule:
    - cron: "*/10 * * * *"   # every 10 minutes
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: scrape-appointmenttrader
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 6

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      # ✅ RESTORE (must be before the scraper)
      - name: Restore state cache
        id: restore_state
        uses: actions/cache/restore@v4
        with:
          path: state.v1.json
          key: state2-v1-${{ github.run_id }}     # unique per run
          restore-keys: |
            state2-v1-                            # get most recent prior cache

      # (optional) sanity check
      - name: Show pre-state
        run: |
          [ -f state.v1.json ] && echo "::group::pre-state" && cat state.v1.json && echo "::endgroup::" || echo "no state"

      - name: Install deps
        run: npm ci || npm install

      - name: Install Playwright
        run: npx playwright install --with-deps chromium

      - name: Run scraper
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          FIRST_RUN: "false"
          SEED_IF_EMPTY: "true"
          DEBUG_LOG: "0"
        run: npm run scrape

      # (optional) verify the state file changed
      - name: Show post-state
        run: |
          [ -f state.v1.json ] && echo "::group::post-state" && cat state.v1.json && echo "::endgroup::" || echo "no state written"

      # ✅ SAVE (only if we didn't already restore an exact match)
      - name: Save state cache
        if: steps.restore_state.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: state.v1.json
          key: state2-v1-${{ github.run_id }}
